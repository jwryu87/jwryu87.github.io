---
layout: default
title: 의사결정나무
parent: 6. ML 평가/검증
grand_parent: AI (인공지능)
nav_order: 10
---

# 의사결정나무(Decision Tree)
{: .fs-8 }

머신러닝 검증
{: .label .label-blue }

---

## 핵심 키워드

`Root Node` `Child Node` `Parent Node` `Branch` `Depth`

---

## 정의/개념

모형의 구축과정을 나무형태로 표현하여 대상이 되는 집단을 몇 개의 소집단으로 구분하는 분류 및 예측 기법

---

## 개념도

```
                    ┌─────────────────┐
                    │  Decision Node  │◄──── Root Node
                    └────────┬────────┘
                             │
            ┌────────────────┼────────────────┐
            │                │                │
    ┌───────┴───────┐       │        ┌───────┴───────┐
    │ Sub-Tree      │       │        │ Decision Node │
    │               │       │        └───────┬───────┘
    │ ┌───────────┐ │       │                │
    │ │Decision   │ │       │        ┌───────┼───────┐
    │ │Node       │ │       │        │       │       │
    │ └─────┬─────┘ │       │        ▼       ▼       ▼
    │   ┌───┴───┐   │       │    ┌──────┐ ┌──────┐ ┌──────┐
    │   ▼       ▼   │       │    │ Leaf │ │ Leaf │ │Decision│
    │ ┌────┐ ┌────┐ │       │    │ Node │ │ Node │ │ Node  │
    │ │Leaf│ │Leaf│ │       │    └──────┘ └──────┘ └───┬───┘
    │ │Node│ │Node│ │       │                          │
    │ └────┘ └────┘ │       │                    ┌─────┴─────┐
    └───────────────┘       │                    ▼           ▼
                            │                ┌──────┐   ┌──────┐
                            │                │ Leaf │   │ Leaf │
                            │                │ Node │   │ Node │
                            ▼                └──────┘   └──────┘
```

---

## 정의 및 구성 요소

### 정의

- 의사결정 규칙을 나무 구조로 나타내어 전체 자료를 몇 개의 소집단으로 분류(classification)하거나 예측(prediction)을 수행하는 분석방법
- 설명변수(X) 간의 관계나 척도에 따라 목표변수(Y)를 예측하거나 분류하는데 활용되는 나무 구조의 모델

### 구성 요소

| 구성 요소 | 설명 |
|:---------|:-----|
| **root node** | 의사결정 Tree가 시작되는 노드 |
| **child node** | 하나의 마디로부터 분리되어 나간 2개 이상의 노드 |
| **parent node** | 주어진 마디의 상위 노드 |
| **terminal node** | 더 이상 분기가 되지 않아 자식 마디가 없는 최종 끝의 노드 |
| **branch** | root node로부터 terminal node까지 연결된 node |
| **depth** | root node부터 terminal node 까지의 중간 node 들의 수 |

---

## 의사결정나무 모델의 절차

| 단계 | 기술 | 설명 |
|:-----|:-----|:-----|
| **성장(Tree Growing)** | ASM(Attribute Selection Measure) | 최대 크기의 나무 모형 형성<br>- 전체 데이터 셋에서 최상의 속성을 탐색 |
| | 분리 규칙 | 전체 데이터 셋에서 각 Node에서 적절한 최적의 분리 규칙 검색 |
| | child node 생성 | 분리 규칙에 따라 하위 집합을 생성 |
| **가지치기(pruning)** | - | 최대 크기 나무모형에서 불필요한 가지를 제거하여 부분 나무모형(subtrees)의 집합을 탐색 |
| **최적 나무 모형 선택** | - | 가지치기의 결과인 나무모형의 집합에서 최적 모형을 선택<br>- 검증오차가 가장 작은 의사결정나무를 평가 |
| **해석 & 예측** | - | 구축된 나무모형을 해석하고 예측모형을 설정한 후 예측에 적용 |

---

## 분리 기준 (Attribute Selection Measure)

| 분리 기준 | 설명 | 알고리즘 |
|:---------|:-----|:--------|
| **지니 지수(Gini Index)** | 불순도 측정, 0에 가까울수록 순수 | CART |
| **엔트로피(Entropy)** | 정보 이득 기반 분리 | ID3, C4.5 |
| **카이제곱 통계량** | 통계적 유의성 검정 | CHAID |

---

## 의사결정나무 알고리즘

| 알고리즘 | 특징 | 분리 기준 |
|:---------|:-----|:---------|
| **CART** | 이진 분리, 회귀/분류 가능 | 지니 지수 |
| **ID3** | 범주형 변수만 | 엔트로피 |
| **C4.5** | ID3 개선, 연속형 처리 | 정보 이득 비율 |
| **CHAID** | 다지 분리, 통계 기반 | 카이제곱 |

---

## 장단점

| 구분 | 내용 |
|:-----|:-----|
| **장점** | 해석 용이성, 시각화 가능<br>비모수적 방법, 전처리 불필요<br>범주형/연속형 모두 처리 |
| **단점** | 과적합 위험성<br>불안정성 (데이터 변화에 민감)<br>경계면이 축에 평행 |

---

## 연계 토픽

- [지니 지수](/docs/ai/01-machine-learning/gini-entropy)
- [엔트로피 지수](/docs/ai/01-machine-learning/gini-entropy)
- [Random Forest](/docs/ai/01-machine-learning/supervised-learning)

---

## 학습 체크리스트

- [ ] 의사결정나무의 정의와 구성요소 이해
- [ ] Tree Growing → Pruning → 최적 모형 선택 프로세스 암기
- [ ] 분리 기준(지니, 엔트로피, 카이제곱) 차이점 파악

---

## 참고자료

- 정보관리기술사 AI 학습자료

