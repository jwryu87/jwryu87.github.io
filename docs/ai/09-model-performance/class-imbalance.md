---
layout: default
title: Class Imbalance
parent: 9. 모델 성능
grand_parent: AI (인공지능)
nav_order: 2
---

# 클래스 불균형(Class Imbalance) 문제
{: .fs-8 }

모델 성능
{: .label .label-yellow }

---

## 핵심 키워드

`과대표집` `과소표집` `임계값 이동` `SMOTE` `ADASYN`

---

## 정의/개념

탐색하는 타깃 데이터의 수가 매우 극소수인 상태

---

## 클래스 불균형 문제

| 구분 | 설명 |
|:-----|:-----|
| **클래스 불균형 정의** | 탐색하는 타깃 데이터의 수가 매우 극소수인 상태 |
| **클래스 불균형 문제** | 클래스가 불균형한 훈련 데이터를 그대로 이용할 경우 과대 적합이 발생하는 문제<br>- 불균형 데이터에서는 **정확도(Accuracy)가 높아도 재현율(Recall)이 급격히 작아지는** 현상 발생 |

### 사례

```
        .  . .  .  .  .
      .  .  .  .  .  .  .
     . .  . .  . .  . . . .
      .  .  . . . .  . .  .
       . . . . . . . . .
            . . . . .
                          ●
    ──────────────────────────▶
    -2.0  -1.5  -1.0  -0.5   0.0   0.5   Fraud

    화재 발생 확률은 1% 이하인 경우, 100개의 데이터 중 1개가 화재이면
    모두 정상으로 예측해도 정확도가 99%이지만 재현율은 작아짐.
```

> 불균형 데이터 처리를 위해 리스케일링(rescaling) 방법을 적용하며 리스케일링 방법으로 과대표집, 과소표집, 임계값 이동 기법이 있음

---

## 해결방안

### 과대 표집(Over-Sampling)

소수 클래스의 데이터를 복제 또는 생성하여 데이터의 비율을 맞추는 방법

```
    ┌─────────────────────┐      ┌─────────────────────┐
    │                     │      │  █ █ █ █ █ █ █ █    │
    │   █ █               │ ───▶ │  █ █ █ █ █ █ █ █    │
    │   Original Dataset  │      │  █ █ █ █ █ █ █ █    │
    └─────────────────────┘      │     Final Dataset   │
                                 └─────────────────────┘
```

| 기법 | 설명 |
|:-----|:-----|
| **랜덤 과대 표집 (Random Over-Sampling)** | 단순 복제 |
| **SMOTE (Synthetic Minority Over-sampling Technique)** | K-NN 기반 합성 데이터 생성 |
| **Borderline-SMOTE** | 경계선 주변 데이터만 SMOTE 적용 |
| **ADASYN (ADAptive SYNthetic)** | 학습 난이도 기반 적응적 생성 |

**특징**:
- 정보가 손실되지 않는다는 장점이 있으나 과적합(Over-fitting) 조래 가능
- 알고리즘의 성능은 높으나 검증의 성능은 나빠질 수 있음
- 과대 표집에서 데이터를 복제할 때 무작위로 데이터를 추출하면 과적합 가능성이 높아 주의 필요

---

### 과소 표집(Under-Sampling)

다수 클래스의 데이터를 일부만 선택하여 데이터의 비율을 맞추는 방법

```
    ┌─────────────────────┐      ┌─────────────────────┐
    │ █ █ █ █ █ █ █ █ █   │      │                     │
    │ █ █ █ █ █ █ █ █ █   │ ───▶ │  █ █ █ █            │
    │   Original Dataset  │      │     Final Dataset   │
    └─────────────────────┘      └─────────────────────┘
```

| 기법 | 설명 |
|:-----|:-----|
| **랜덤 과소 표집 (Random Under-Sampling)** | 무작위 제거 |
| **ENN (Edited Nearest Neighbor)** | 이웃 기반 노이즈 제거 |
| **토멕 링크 방법 (Tomek Link Method)** | 경계 샘플 제거 |
| **CNN (Condensed Nearest Neighbor)** | 대표 샘플만 유지 |
| **OSS (One Sided Selection)** | 토멕 + CNN 결합 |

**특징**:
- 데이터의 소실이 매우 크고, 때로는 정상 데이터를 잃을 수 있음
- 과소 표집은 일반적으로 과대 표집보다 계산 시간이 감소함
- 과소 표집에서 데이터의 일부만 선택하면 중요한 정보 손실이 발생할 수 있어 주의 필요

---

## 연계 토픽

- [Confusion Matrix](/docs/ai/06-ml-evaluation/confusion-matrix)
- [모델 평가](/docs/ai/06-ml-evaluation/model-evaluation)
- [Precision & Recall](/docs/ai/06-ml-evaluation/precision-recall)

---

## 학습 체크리스트

- [ ] 클래스 불균형 문제의 정의와 영향 이해
- [ ] 과대 표집 vs 과소 표집 차이점 파악
- [ ] SMOTE, ADASYN 등 기법 암기

---

## 참고자료

- 정보관리기술사 AI 학습자료
