---
layout: default
title: Bias · Variance
parent: 9. 모델 성능
grand_parent: AI (인공지능)
nav_order: 3
---

# 편향(Bias), 분산(Variance)
{: .fs-8 }

모델 성능
{: .label .label-yellow }

---

## 핵심 키워드

- **편향**: 예측값, 실제값
- **분산**: 예측값, 예측값

---

## 정의/개념

- **편향(Bias)**: 예측값 평균과 실제값의 차이
- **분산(Variance)**: 예측값 평균과 예측값의 차이

---

## 개념 비교

| 구분 | 편향(Bias) | 분산(Variance) |
|:-----|:-----------|:---------------|
| **개념** | 예측값 평균과 실제값(측정값)의 차이 | 예측값 평균과 예측값의 차이 |
| | 예측값과 실제값의 오차 정도 | 예측값이 흩어진 정도 |
| **수식** | 편향(Bias) = E[f(x) - f̂(x)] | 분산(Variance) = E[(f(x) - E[f(x)])²] |
| | f(x): 예측값, f̂(x): 실제값 | f(x): 예측값 |

---

## 편향과 분산의 개념도

```
     Low Variance       High Variance
    ┌─────────────┐   ┌─────────────┐
    │  ●  ●       │   │  ●      ●   │
    │    ⊙  ●     │   │    ⊙       │     ⊙ : 실제값
    │  ●      ●   │   │ ●    ●     │     ● : 예측값
    │      ●      │   │   ●    ●   │
    └─────────────┘   └─────────────┘
       Low Bias          Low Bias

    ┌─────────────┐   ┌─────────────┐
    │             │   │  ●      ●   │
    │  ● ● ⊙     │   │         ⊙  │
    │  ● ●        │   │    ●       │
    │             │   │ ●    ●     │
    └─────────────┘   └─────────────┘
      High Bias         High Bias
```

---

## 편향과 분산의 Trade-off

```
    Error
      │                           
      │                    Total Error
      │\                  /
      │ \                /
      │  \    최적값    /
      │   \    ↓      /
      │    \   ●     / 
      │     \ / \   /   Variance
      │      ╲   ╲ /
      │       ╲   ╲
      │        ╲   ╲
      │         ╲   ╲
      │          Bias²
      └────────────────────────────▶
                      모델 복잡성
```

> 편향과 분산은 Trade-off 관계를 가지며, AI 학습 모델 및 빅데이터 분석 모델의 모델 복잡성을 최적화하기 위한 주요 요소로 활용

> MSE(Mean Squared Error) 공식으로부터 편향과 분산의 Trade-off 관계 도출

---

## 편향과 분산값에 따른 학습모델 특성

| 편향(Bias) | 분산(Variance) | 학습모델 특성 |
|:-----------|:--------------|:-------------|
| **높음** | 낮음 | 특정 데이터만 학습(Underfitted)<br>- 모델 복잡성 낮음 |
| **중간** | 중간 | 데이터 골고루 학습<br>- 모델 복잡도 적정 |
| **낮음** | 높음 | 데이터 과학습(Overfitted)<br>- 모델 복잡도 높음 |

> 최적 성능의 AI & 빅데이터 분석 모델 도출 위해 적정 수준의 데이터 학습 필요

---

## 최적 학습모델 도출방안

| 구분 | 도출 방안 | 설명 |
|:-----|:---------|:-----|
| **높은 분산, 낮은 편향인 경우 (오버피팅)** | Drop Out | 주요 노드 가중치만 연산 |
| | 앙상블(Ensemble) 기법 | 보팅(Voting), 배깅(Bagging), 부스팅(Boosting), 랜덤 포레스트(Random Forest) |
| | 차원 축소 | 특성(Features) 축소 |
| | 충분 데이터 학습 | Train Validation, Cross Validation |
| | 학습 조기 종료 | 검증 정확도 미상승시 종료 |
| | 정규화 계수값 및 높낮이 | 지나친 정규화로 인한 언더피팅(Underfitting) 완화 |
| **높은 편향, 낮은 분산인 경우 (언더피팅)** | 특성 강화 | 불완전 특성 데이터 셋 보완 |
| | XAI 도입 | 머신러닝 파이프라인 결함으로 인한 학습저하 대응 |
| | 활성화 함수 변경 | 기울기 소실로 인한 전달값이 사라지는 문제 해결<br>- ReLU(Rectified Linear Unit), Leaky ReLU |

> 정규화(계수값 조정)를 통해 분산과 편향을 조정하여 적정 수준 모델 도출

---

## 연계 토픽

- [과적합/과소적합](/docs/ai/01-machine-learning/overfitting-underfitting)
- [정규화](/docs/ai/01-machine-learning/parameters)
- [Cross Validation](/docs/ai/06-ml-evaluation/cross-validation)

---

## 학습 체크리스트

- [ ] 편향과 분산의 정의와 차이 이해
- [ ] Trade-off 관계 파악
- [ ] 최적 모델 도출방안(Dropout, 앙상블, 정규화 등) 암기

---

## 참고자료

- 정보관리기술사 AI 학습자료
