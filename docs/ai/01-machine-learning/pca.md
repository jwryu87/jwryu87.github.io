---
layout: default
title: PCA
parent: 1. 기계학습
grand_parent: AI (인공지능)
nav_order: 19
---

# PCA(Principal Component Analysis)
{: .fs-8 }

1.3 비지도학습
{: .label .label-green }

---

## 핵심 키워드

`공분산` `Eigen Vector` `Eigen Value`

---

## 정의/개념

고차원에서 저차원 차원 축소, 잡음 제거, 전처리 작업 사용, 공분산 사용 비지도 학습 알고리즘

---

## 개념도

```
  <3차원>                    <2차원>
    PC1                        
   ╱ │╲                     PC1 ───→
  ● ●│●●         PCA         ●●●●
 ●●●●│●●●      ────→       ●●●●●●
  ●●●│●●                    ●●●●
    PC2                        │
                              PC2
```

---

## 주요 수식

| 구분 | 수식 | 설명 |
|:-----|:-----|:-----|
| **공분산** | $$\frac{\sum(X - \bar{X})(Y - \bar{Y})}{(n-1)}$$ | 두 확률 변수의 상관관계를 나타내는 값<br>C>0: 양의 상관관계<br>C<0: 음의 상관관계<br>C=0: 두 변수는 독립임 |
| **Eigen Vector** | $$A_x = \lambda x$$ (x: Eigen Vector) | 행렬 A를 선형변환한 결과가 자기 자신의 상수배가 되게 하는 벡터 |
| **Eigen Value** | $$A_x = \lambda x$$ (λ: Eigen Value) | 행렬 A를 선형변환한 결과가 자신의 상수배가 되게 하는 값 |

> PCA는 LDA와 같이 얼굴인식 구성 시 대표적으로 쓰이는 알고리즘

---

## 프로세스

1. **데이터 정규화**: 다차원 데이터의 변수들 간에 스케일이 서로 다르면 PCA 수행 시 각 변수의 기여도가 달라질 수 있으므로, 각 변수의 평균을 0, 표준편차를 1로 정규화한다.

2. **공분산 행렬 계산**: 정규화된 데이터에 대해 공분산 행렬을 계산한다. 이 때 공분산 행렬은 각 변수들 간의 상관관계를 계산한 것으로, 대각원소는 각 변수의 분산을 나타내고, 비대각원소는 두 변수 간의 공분산을 나타낸다.

3. **고유값 분해**: 공분산 행렬에 대해 고유값(eigenvalue)과 고유벡터(eigenvector)를 구한다. 이 때 고유값은 공분산 행렬의 주성분에 대한 중요도를 나타내고, 고유벡터는 주성분의 방향을 나타낸다.

4. **주성분 선택**: 고유값이 큰 순서대로 주성분을 선택하고, 선택한 주성분으로 이루어진 새로운 데이터 공간을 생성한다.

5. **데이터 변환**: 선택한 주성분으로 이루어진 데이터 공간으로 데이터를 변환한다.

---

## 연계 토픽

- [LDA](/docs/ai/01-machine-learning/pca)

---

## 학습 체크리스트

- [ ] PCA의 정의와 목적 이해
- [ ] 공분산, Eigen Vector, Eigen Value 개념 파악
- [ ] PCA 프로세스 5단계 암기

---

## 참고자료

- 정보관리기술사 AI 학습자료
