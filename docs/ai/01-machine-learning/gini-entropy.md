---
layout: default
title: 지니/엔트로피 지수
parent: 1. 기계학습
grand_parent: AI (인공지능)
nav_order: 15
---

# 지니 지수(Gini Index), 엔트로피 지수(Entropy Index)
{: .fs-8 }

1.2 지도학습
{: .label .label-purple }

---

## 핵심 키워드

`의사결정나무` `이산형 목표변수` `불순도 측정`

---

## 정의/개념

**의사결정나무**: 모형의 구축과정을 나무형태로 표현하여 대상이 되는 집단을 몇 개의 소집단으로 구분하는 분류 및 예측 기법

---

## 지니 지수(Gini Index)

| 구분 | 설명 |
|:-----|:-----|
| **개념** | 불순도를 측정하는 지표로, 데이터의 통계적 분산정도를 정량화하여 표현한 값 |
| **수식** | $$G(S) = 1 - \sum_{i=1}^{c} p_i^2$$ |
| **설명** | S: 이미 발생한 사건의 모음, c: 사건의 갯수<br>영역 내에서 특정 클래스에 속하는 관측치들의 비율을 제외한 값 |

### 지니 지수 특성

- Gini Index가 높을수록 데이터가 분산되어 있음을 의미
- Decision Tree는 지니 불순도를 낮추는 방향으로 가지치기 진행
- 불순도를 수치화한 지표는 지니 지수와 엔트로피 지수가 존재

---

## 엔트로피 지수(Entropy Index)

| 구분 | 설명 |
|:-----|:-----|
| **개념** | 불순도를 측정하는 지표로, log를 취하여 정규화 과정을 통해 무질서한 정도를 정량화(수치화)한 값 |
| **수식** | $$Entropy(A) = -\sum_{k=1}^{m} p_k \log_2(p_k)$$ |

### 엔트로피 지수 해석

| 조건 | 의미 |
|:-----|:-----|
| 엔트로피(Entropy) 수치가 0일 경우 | 분류에 속하는 개체 속성이 모두 동일 |
| 엔트로피(Entropy) 수치가 1에 가까울 경우 | 불순도가 높음 |
| 엔트로피(Entropy) 수치가 0에 가까울 경우 | 불순도가 낮음 |

---

## 주요 특징

- 불순도와 엔트로피(Entropy)는 비례관계라 볼 수 있음
- 의사결정나무 모델은 각 노드의 순도가 증가하거나 불순도가 감소하도록 하는 방향으로 학습진행하여 **엔트로피를 이용하여 정보획득량을 구하게 됨**

---

## 연계 토픽

- [의사결정나무](/docs/ai/06-ml-evaluation/cross-validation)

---

## 학습 체크리스트

- [ ] 지니 지수와 엔트로피 지수의 정의 이해
- [ ] 수식과 계산 방법 파악
- [ ] 의사결정나무에서의 활용 방법 이해

---

## 참고자료

- 정보관리기술사 AI 학습자료


