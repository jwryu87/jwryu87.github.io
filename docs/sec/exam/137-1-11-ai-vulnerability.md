---
layout: default
title: 137회-1교시-11번 인공지능 시스템의 취약점
parent: 📝 기출문제
grand_parent: SEC (정보보안)
nav_order: 137111
permalink: /docs/sec/exam/137-1-11-ai-vulnerability
---

# 인공지능 시스템의 취약점
{: .no_toc }

137회 정보관리기술사 1교시 11번
{: .label .label-blue }

인공지능 / 난이도: 중
{: .label .label-green }

1교시형 (단답형)
{: .label .label-purple }

---

## 📚 목차
{: .no_toc .text-delta }

- [🎓 고딩 수준 설명](#-고딩-수준-설명)
- [🎯 기술사 수준 설명](#-기술사-수준-설명)

---

<details markdown="1">
<summary><h2 style="display:inline" id="-고딩-수준-설명">🎓 고딩 수준 설명 (클릭해서 펼치기)</h2></summary>

### 🔑 핵심 키워드 3개
- **데이터 오염**: AI가 배우는 데이터에 나쁜 것을 섞는 것
- **적대적 공격**: AI를 속이기 위해 일부러 조작하는 것
- **모델 탈취**: AI의 비밀을 훔쳐내는 것

### 📖 등장배경

> ChatGPT 같은 AI가 엄청 똑똑해졌는데, 해커들이 AI를 속이는 방법을 찾아냈어요. 예를 들어 고양이 사진에 아주 작은 점 몇 개만 추가해도 AI가 "이건 토스터기야!"라고 잘못 판단하게 만들 수 있어요. 이렇게 **AI도 해킹당할 수 있다**는 걸 알게 되면서 AI 보안이 중요해졌어요!

### 📝 개념 정의

> AI 취약점은 **"AI 시스템이 공격받을 수 있는 약점"**이에요.
> 
> 비유하자면, 아무리 똑똑한 학생도 **시험지에 이상한 문제가 섞여있으면 틀릴 수 있는 것**과 같아요!

### 🏗️ 기술요소 (2그룹)

**그룹 1: 적대적 공격 종류**

| 공격 | 쉬운 설명 | 목표 |
|:-----|:---------|:-----|
| Poisoning | 학습 데이터에 독을 타는 것 | AI 망가뜨리기 |
| Evasion | AI 눈을 속이는 것 | 오분류 유도 |
| Inversion | AI 기억을 역추적하는 것 | 데이터 탈취 |
| Model Extraction | AI 뇌를 복사하는 것 | 모델 탈취 |

**그룹 2: 방어 기법**

| 방어 | 쉬운 설명 | 효과 |
|:-----|:---------|:-----|
| 적대적 훈련 | 해킹 데이터로 미리 연습 | AI 면역력 강화 |
| Defense-GAN | 변조 이미지 복원 | 정상 이미지로 변환 |
| 쿼리 제한 | 질문 횟수 제한 | 탈취 공격 방지 |

### ⭐ 차별점 키워드

> **OWASP Top 10 for LLM**: LLM(대형언어모델)의 10대 보안 위협 목록!

### 📋 6하원칙 요약

| 구분 | 내용 |
|:-----|:-----|
| **누가** | 해커, 공격자, 악의적 사용자 |
| **무엇을** | AI 모델, 학습 데이터, 추론 결과 |
| **언제** | 개발~운영 전 단계 |
| **어디서** | 데이터 수집, 학습, 배포, 운영 환경 |
| **왜** | 데이터 탈취, 모델 무력화, 오분류 유도 |
| **어떻게** | 데이터 오염, 적대적 예제, 쿼리 공격 |

</details>

---

## 🎯 기술사 수준 설명
{: #-기술사-수준-설명}

{: .highlight }
> **AI 시스템 취약점**: 데이터조작, 모델왜곡, 적대적공격 → AI 시스템 보안 위협
> - (개발단계) `요데모` (요구사항→데이터→모델)
> - (적대적공격) `PEIM` (Poisoning, Evasion, Inversion, Model extraction)
> - (방어기법) `적결탐쿼D`

---

### 📝 개념 정의

인공지능 시스템 활용 확대에 따른 보안 위협과 대응 방안이 중요해짐에 따라,
데이터·모델·운영 환경의 약점을 악용하여 **AI 시스템의 오동작을 유발하거나 정보를 탈취하는 취약점**

| 구분 | 설명 |
|:-----|:-----|
| 정의 | AI 운영 신뢰성을 저해하는 시스템 약점 (18자) |
| 참조 | OWASP Top 10 for LLM Applications 2025 |
| 대응 | SAIF(Secure AI Framework) 기반 보안 체계 |

---

### 🔄 AI 시스템 개발 주기별 취약점

```
요구사항/설계 ──▶ 데이터 수집 ──▶ 모델 학습/검증 ──▶ 배포/운영 ──▶ 유지보수
     │              │              │              │            │
     ▼              ▼              ▼              ▼            ▼
 프라이버시     데이터 편향      과적합       적대적 공격    Drift
 설계 부재     Poisoning     AI 공급망     프롬프트 인젝션  패치 지연
```

---

### 🏗️ 구성요소

#### 개발 단계별 취약점 `요데모`

| 단계 | 취약점 | 설명 |
|:-----|:------|:-----|
| **요**구사항/설계 | 프라이버시 설계 부재 | 민감정보 처리 방침, 데이터 보호 기술 초기 설계 미흡 |
| | 법/컴플라이언스 미고려 | 개인정보보호, AI 관련 법적 규제 고려 미흡 |
| **데**이터 수집/전처리 | 데이터 편향 | 학습 데이터가 특정 집단을 과소/과대 대표 |
| | 데이터 오염·주입 공격 | 악의적 데이터(트리거)를 학습 데이터에 삽입 |
| **모**델 학습/검증 | 과적합(Overfitting) | 학습 데이터에 최적화되어 검증 데이터 성능 저하 |
| | AI 공급망 취약점 | 외부 라이브러리/프레임워크에서 악성 공격 침투 |

#### 적대적 공격 유형 `PEIM`

| 공격 | 대상 | 설명 |
|:-----|:-----|:-----|
| **P**oisoning Attack | 무결성 | 악의적인 학습 데이터를 주입해 모델을 망가뜨리는 공격 |
| **E**vasion Attack | 무결성 | 입력 데이터에 최소한의 변조로 오분류를 유도하는 공격 |
| **I**nversion Attack | 기밀성 | 쿼리 결과를 분석해 학습 데이터를 역으로 추출하는 공격 |
| **M**odel Extraction | 기밀성 | 반복 쿼리로 출력 결과를 분석해 모델을 복제하는 공격 |

#### 운영 단계 추가 취약점

| 취약점 | 설명 |
|:------|:-----|
| 프롬프트 인젝션 | LLM 입력 프롬프트에 악의적인 명령을 주입하는 공격 |
| DoS/DDoS | 대량 트래픽으로 AI 시스템 가용성 저해 |
| Data Drift | 입력 데이터 분포 변화로 성능 저하 |
| Concept Drift | 입력-출력 관계 변화로 성능 저하 |

---

### 🛡️ 대응 방안 `적결탐쿼D`

| 방어 기법 | 설명 |
|:---------|:-----|
| **적**대적 훈련 | 예상 가능한 해킹 데이터를 포함해 ML 저항성 강화 |
| **결**과값 분석 차단 | 학습모델 결과값 노출 방지 또는 분석 불가 변환 |
| **탐**지 모델 추가 | 별도 모델로 적대적 공격 여부 비교·탐지 |
| **쿼**리 횟수 제한 | Inversion/Model Extraction 공격 방어 |
| **D**efense-GAN | GAN으로 변조 이미지를 정상 이미지로 복원 |

---

### 🔧 단계별 대응 체계

| 단계 | 대응방안 | 상세 |
|:-----|:--------|:-----|
| 요구사항/설계 | 데이터 거버넌스 | AI 위협 모델링 수행 |
| 데이터 수집 | 무결성 검증 | 차등프라이버시 적용 |
| 모델 학습/검증 | 정규화 | 적대적 훈련 수행 |
| 배포/운영 | MLOps | 샌드박스 환경 운영 |
| 유지보수 | SBOM 적용 | Drift 모니터링 |

---

### ⭐ 차별점 키워드

> **SAIF (Secure AI Framework)**
> - Google 제안 AI 보안 프레임워크
> - AI 시스템의 기밀성·무결성·가용성 확보를 위한 통합 대응 체계

---

### 📈 상위 토픽 계층도

```
정보보안 / 인공지능
├── AI 보안
│   ├── AI 시스템 취약점 ← 현재 토픽
│   ├── 적대적 공격 (Adversarial Attack)
│   └── AI 거버넌스
├── AI 보안 프레임워크
│   ├── SAIF (Google)
│   └── OWASP Top 10 for LLM
└── MLOps / AI 운영
    └── Drift 모니터링
```

---

### ✅ 학습 체크리스트

- [ ] AI 시스템 취약점의 정의를 한 문장으로 말할 수 있다
- [ ] 개발 단계별 취약점(요데모)을 설명할 수 있다
- [ ] 적대적 공격 4가지(PEIM)를 열거할 수 있다
- [ ] 방어 기법 5가지(적결탐쿼D)를 나열할 수 있다
- [ ] SAIF의 의미를 설명할 수 있다

